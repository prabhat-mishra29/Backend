[Check out the data modeling structure of mega project in eraser.io]

#Project Structure Steps:-

    1.Create package.json using npm init.

    2.Let's discuss how we store our images?
        > We will upload the photos to AWS, Cloudinary, and Azure. The platforms will respond to an API to be used for future cases..
        >But sometimes user loses their connection so better way to store these photos and videos in our temporary server. After that, we use some processes to put these images into AWS, Cloudinary, and Azure.

    3.Create a 'public' folder then create a 'temp' folder inside it.

    4. Git tracks files, not folders. If you create a folder inside another folder and try to push it to GitHub, an empty file will be displayed. 
        > So how will you do then ?
        > Using '.gitkeep' , It is an empty file.

    5.Create .gitignore, .env file and .env.sample .
        > You can ignore project files for a specific project using "git ignore generators".

    6.Create a 'src' folder in main/root.within that create app.jsx file , index.js file and constants.js file.

    7.Go to the package.json and make 'type' as 'module'.
        >Whenever server file reloads , we need to stop and restart the server.Do we really want to do everytime?
        >No, We use 'nodemon'.
        >'nodemon' is a tool that helps develop Node.js based applications by automatically restarting the node application when file changes in the directory are detected.
        >Here we install nodemon as a development dependency:
            "npm install --save-dev nodemon"
        >'Dev dependencies' are packages that are only required for local development and testing, and not for the production environment.
        >After installing nodemon, we need to direct it so that it automatically restarts whenever we hit 'npm run dev'. [go to the package.json]

    8.Go to src and create "controllers folder"[functionality] , "db folder"[database connection logic] , "middlewares folder"[It is a function that is executed between the request and response cycles of an application.{like it checks your cookies to see if you can get your information from response or not?}] , "models folder"[data modeling] , "routes folder"[routing] , "utils folder"[utility:-joo functionality baar baar repeat hoga usko ekk separate file pai rakhke,jahan v jarurat hoo use kiya jaye.]

    9.what is the use of prettier?
        > Prettier ensures consistency in your code formatting and makes the process automatic.
        > Learn about prettier.
        > install dev-dependency of prettier :- npm install -D prettier
        > add some additional file:- '.prettierrc' and '.prettierignore'


# How to connect database steps:-
    > Here we use mongoDB online service i.e 'mongoDB atlas'.
    
    1.Go to mongoDB atlas and make your account.

    2.To learn how to create your account and access other features, please refer to video number 7.

    3.In MongoDB, a cluster is a server instance that is formed by multiple instances of MongoDB code running through sharding and/or replication.

    4.In most cases, we deal with network and database access.
        network access:-Create your IP address.
        database access:-Create a database user.

    5.When connecting to MongoDB, you need an IP address, a username with a password, and a String.
        >String comes when you connect to cluster0 using compass or various methods. [mongoDB URL]

    6.Go to the .env file and save your mongoDB URL in it.

    7.Please access the constants file and create a name for the database. Then, export the created name.

    8.install 'dotenv','express','mongoose' package.

    9."Two things you must remember befor connecting with database":-
        >"Database is always in another continent."
        >Use try-catch and promises[resolve and reject] for avoiding errors.

    10.Mongoose is the one using which we can connect our database.

    11.We have two options for database connection.
        >1st one is we insert all codes to the index.js file and then execute. Whenever that data-connection code hits it executes immediately.
        
        >2nd one is create a DB folder and insert your connection code there , then import this folder to index.js file.

        >We use 2nd one.
    
    12.Go to the index.js and connect your database using mongoose. [for 1st approach]

    13.Go to the DB folder.[For 2nd approach]

    14.Go to 'app.js' and create an express app then import it on index.js.

    15.You may encounter an error stating that the file cannot be imported. If this occurs, always check your import statement. If the extension is missing, make sure to add it. [like db.js,constants.js etc]

    16.Agar .env pai kuch change hua toh dubara reload karo.

    17.If you get this error:-MongooseServerSelectionError: Could not connect to any servers in your MongoDB Atlas cluster. One common reason is that you're trying to access the database from an IP that isn't whitelisted.
        >Simply switch between wifi and mobile data to fix the issue.


# Custom API response and error handeling:-
    1.Generally, we lie in two states i.e. request and response of expressJS.

    2.Learn everything about request and response properties in expressJS documentation.

    3.In our observation, we consider only req.body,req.cookies and req.params.

    4.install 'cookie-parser' middleware and 'cors'.
        >CORS is a node.js package for providing a Connect/Express middleware that can be used to enable CORS with various options.
            - "app.use()" -> it is used when we have a middleware or configuration.

        >Cookie parser typically performs the following tasks: Extracts the cookie data from the HTTP request and converts it into a usable format that can be accessed by the server-side code.

    5.Go to 'app.js' and check out how to use CORS , cookie-parser and set some rules for data which comes from different resources.

    6.Draw a diagram to understand middleware in eraser.io .
        >Some information need to be updated:-
            app.get('/instagram', (err,req,res,next) => {
                res.send('Hello World!')
            })
            - 'next' serves as a flag to pass on the reference to the next middleware until it reaches the response part.

    7.We always talk with database.[like in user controller , video controller etc]
        > Database is in another continent.
        > Did we need to use the database connection code again and again? :- No , To simplify this process, we create a utility file. This file can be imported whenever we need to use its functions or methods.
        > It acts as a wrapper.
            - We can use two different ways to do this.1st one is asyncHandler[using promises] and second one is try-catchHandler.

            - Go to utility folder -> asyncHandler.

    8.Now it is the time for creating a centralized format for handling errors.learn NodeJS API error. It returns a error-class.By overriding different methods we can improve error handling.
        - Go to utility folder -> APIerror

    9.For handling responses we do not use nodeJS because we have expressJS.But we can create a separate class for that and implement it for our use.
        - Go to utility folder -> APIresponse
    
    10.Learn about http status code.


# User and video model with hooks and JWT:-
    1.Go to eraser.io and watch user and video model.

    2.Create user model and video model in 'models' folder.

    3.Here we use a special type of package called "mongoose-aggregate-paginate-v2".
        > It is a pagination library designed specifically for handling paginated results from MongoDB aggregation queries in a Node.js application using Mongoose.

        > Pagination in MongoDB is a way to divide a large dataset into smaller, more manageable pieces.
        
        > In the context of databases, aggregation refers to the process of transforming and combining data from multiple documents or rows into a single result set based on specified criteria.  
        
        > MongoDB's aggregation framework operates using a pipeline model, where data flows through multiple stages of transformation. Each stage in the pipeline performs a specific operation on the data, such as filtering, grouping, or projecting, and passes the results to the next stage.

        > We will study this later.

        > Use:-Go to video.model.

    4.For password encrypted-decrypted problem:- We use bcrypt/bcrypt.js.
        > A library to help you hash passwords.
            > bcrypt:-A bcrypt library for NodeJS.
            > bcrypt.js:-Optimized bcrypt in plain JavaScript with zero dependencies. Compatible to 'bcrypt'.
                - Both have same functionality.Which one would you prefer,it depends on you.
                - Here we use core 'bcrypt'.Install 'bcrypt'.

        
    5.For tokens we use JWT:-
        > JSON Web Tokens (JWTs) are a standardized way to securely send data between two parties. They contain information (claims) encoded in the JSON format. These claims help share specific details between the parties involved.
        > Learn about it on JWT.io .
        > Install jsonwebtokens .

    6.Both bcrypt and jsonwebtokens uses cryptography.

    7.Go to user.model and see how to use bcrypt,jsonwebtokens.

    8.Learn middleware , types middleware and methods from mongoose documentation.
        > Mongoose has 4 types of middleware: document middleware, model middleware, aggregate middleware, and query middleware.

    9.Learn difference bewtween access token vs referesh token.


# How to upload file in backend | Multer :-
    1.File handling doest not do in your own server , it uses either third party resources or AWS.Depend upon file size,calculation rate we choose resources.

    2.We make a separate utility/middleware for file uploader.We can use same code for image upload,pdf upload,video upload.
        > Depending on the type of end-points, we utilize middleware to interact with these end-points.

    3.We use 'cloudinary'.Create your own account and install it on VS-code.
    
    4.Strtegy to upload file:-
        > We will store these photos and videos in our temporary server.
        > After that, we use some processes to put these images into AWS, Cloudinary, and Azure.

        steps:-
            > Initially, we assumed that the file had already been uploaded to the local server, which gave us a local path.
            > using this local path we upload the file in 'cloudinary'.
            >After successfuly upload , we unlink/remove the file from local server.
            >Go to cloudinary.js .

    5.When you upload file,you got two packages.We use one of them.
        > 'express-fileupload' or 'multer'.We use 'multer'.
        > Install multer.

        > Multer is a node. js middleware for handling multipart/form-data , which is primarily used for uploading files from clients to the server in Node.js applications, typically in combination with frameworks like Express.js. 

        > We will create a middleware using multer.We directly configure multer but via middleware we can utilize it more effectively.

        > When we need this middleware we can import it. like in registration form.

        > Go to middleware and create 'multer' middleware for storing in disk storage.
        > Here we learn how to save 'file' in diskStorage.
        > learn about multer and how to use, how to upload in freecodecamp.


# HTTP crash course :-
    1.Hypertext Transfer Protocol.

    2.In 'HTTP' data goes in clear form.

    3.HTTPS is HTTP with encryption and verification.
    
    4.The only difference between the two protocols is that HTTPS uses TLS (SSL) to encrypt normal HTTP requests and responses, and to digitally sign those requests and responses.

    5.URI, URL, and URN are all types of strings that identify resources on the internet. 
    
    6.URI stands for Uniform Resource Identifier, URL stands for Uniform Resource Locator, and URN stands for Uniform Resource Name.

    7.HTTP headers:-
        >meta data.
        >HTTP headers let the client and the server pass additional information with an HTTP request or response.
        >Working:- Caching, authentication[bear token,refresh token,refresh key,refresh secret], manage state[user's state:-guest user,login user].
        >Types:-
            -Request headers:-
                Contain more information about the client requesting the resource.

            -Response headers:-
                Hold additional information about the response, like its location or about the server providing it.

            -Representation headers:-
                Contain information about the body of the resource, like its MIME type, or encoding/compression applied.
            
            -Payload headers:-
                Contain information about payload data, including content length and the encoding used for transport.

    8.Most common headers:-
        >Accept :- konsa format accept hoga.[ application/json or text/html ]
        >User-Agent :- konsi application se request ayaa hai.[ postman or browser{which type browser?} ]
        >Authentication :- [Bear_token]
        >Content-type :- which type content. [Images or videos]
        >Cookie :- [key value pair]
        >Cache-Control

    9.CORS headers:-
        >Access-Control-Allow-Origin
        >Access-Control-Allow-Credentials
        >Access-Control-Allow-Method

    10.Security policies headers:-
        >Cross-Origin-Embedder-Policy
        >Cross-Origin-Openers-Policy
        >Content-Security-Policy
        >X-XSS-Protection

    11.HTTP methods:-
        >Basic set of operations that can be used to interact with server.

            [ Most common :- GET , POST , PUT , DELETE , PATCH ]
            -GET :- retrieve a resource.
            -HEAD :- No body message,response headers only.
            -OPTIONS :- what operations are available.
            -TRACE :- loopback test (get some data)
            -DELETE :- remove a resource.
            -PUT :- replace a resource.
            -POST :- interact with resource (mostly add to server)
            -PATCH :- change part of a resource.

    12.HTTP response status codes:-
        >It indicate whether a specific HTTP request has been successfully completed. 
        >Responses are grouped in five classes:-
            -Informational responses (100 – 199)
            -Successful responses (200 – 299)
            -Redirection messages (300 – 399)
            -Client error responses (400 – 499)
            -Server error responses (500 – 599)

            100 - continue
            102 - processing
            200 - ok
            201 - created
            202 - accepted
            307 - temperary redirect
            308 - permanent redirect
            400 - bad request
            401 - unauthorized
            402 - payment required
            404 - not found
            500 - internal server error
            504 - gateway time out


# Complete guide for router and controller with debugging :-
    1. Controller:-is a part of the software that handles user inputs and makes decisions about what data should be presented to the user and how it should be presented.

    2. Router:-A router is a networking device that forwards data packets between computer networks. 

    3. Create a 'register' method. Go to user.controller.

    4. Now it is time for 'routers'.Go to routes and create user-routes.We perform all user related routes here.

    5. Import all routers in 'app.js'.

    6. We have many options for 'api-testing'.
        >We can use 'thunder-client' vs-code plugin.
        >We can use 'Post-man'.(we use this)
            - create your account in postman and test "http://localhost:8000/api/v1/users/register" in it's collection.

    7. In this module we just get basic guide for router and controller.In the next module, we will briefly discuss about it's use.


# Logic building | Register controller:-
    1. Now it is the time for building your logic.How to approach a problem.

    2. We just simply breakdown big problem to small problem. 

    3. Here problem is that we have to create a register method for user.[for backend purpose]

    4. Go to "user.controller" and see the work flow.

    5. Important:-
        > const{fullName , email , userName , password}=req.body();
            - {fullName, email, userName, password}: This is object destructuring syntax. It's a way to extract specific properties from an object and assign them to variables with corresponding names. In this case, it's extracting the fullName, email, userName, and password properties from the req.body object.


# How to use postman for backend :-
    1. In this module we first debug our code and check that our code is running properly or not.

    2. "http://localhost:8000/api/v1/users/register".

    3. Why can not we use 'raw' -> 'josn' here just like we did in previous module (in user.controller file) ?
        > Because In this format we can only use data not files.
        > For that we use 'form-data'.

    4. Go to "postman" then choose body , then form data.
        > you can enabel "content-type" as your wish.
        > Set "keys" as 'userName','fullName','email','password','avatar','coverImage' .
        > Make sure you add '✅' mark.
        > Post the data and see the result in postman and mongoDB atlas.We will see that password and refreshToken are not present in "Postman" .
        
    5. After successfuly upload in cloudinary now it is the time to unlink/remove file from server. [in cloudinary.js]

    6.How to configure the postman.
        > watch video number 15.


# Work flow of registerUser:-
    1. At 1st we have a form in home page.

    2. To create the HTML form, you will use the < form > element with the following attributes:
        > action: This attribute specifies the URL or route where the form data will be sent when the form is submitted. In this case, you will set the action attribute to '/register'.

        > method: This attribute specifies the HTTP method to be used when submitting the form. For file uploads, you should use the POST method, as it allows larger amounts of data to be sent. So, set the method attribute to "POST".

        > enctype: This attribute specifies the content type used to submit the form data. For file uploads, you need to set the enctype attribute to "multipart/form-data". This encoding type is necessary for browsers to properly handle file uploads.

    3. After submitting form user is directed to '/register' route. 

    4. Before giving some inforamtion by server , middleware checks .

    5. In our case middleware is "multer" which upload your file in our server. It is stored in "./public/temp".

    6. We use the "POST" method for adding the data to the HTTP routes.

    7. Server access all datas and file by use of express 'req' and give appropriate response by use of 'res'. 

        > app.use("/api/v1/users",userRouter);

        > router.route("/register").post(
        upload.fields(
            //It takes an array of objects.
            [
                {
                    name:"avatar",
                    maxCount:1 //how many numbers of image you want? 
                },
                {
                    name:"coverImage",
                    maxCount:1 //how many numbers of image you want? 
                }
            ]
        ),
        registerUser);

        > registerUser method takes 'req' and give some 'res' to the user.


# Access Refresh Token, Middleware and cookies in Backend :-
    Part-1:-
        > difference between access token and refresh token:--
            - Access token is a shortlived token where as refresh token is a longlived token.
            - Access token doesnot save in database but refresh does.
            - Learn from descope.
            
        > Now it is the time for creating "loginUser" and "logoutUser".Go to the user.Controller.js.

        > We will create a custom middleware for logout service.[go to auth.middleware.js].

        > After creating the auth.middleware.js, proceed to the usre.routes to inject it.

    Part-2:-
        > Debugg "loginUser" and logoutUser" [user.controller.js]

        > Agar access token ka session expire hogaya hai toh frontend bala ek aur request bhej ke access token ko phir se create karr deta hai.
            - Agar access token expire hogaya,toh 401 request ayega.Dubara user ko login karna na pade toh frontend bala cookies se refresh token leke ek request bhejta hai.["endpoint hit karega"]
            - Agar bheja gaya refresh token and database main rakha refresh token same hai toh fir se ek aur access token generate hota hai.
            - We will create an endpoint,where user can refresh it's expiry. [user.controller.js {refreshAccessToken}]

            - Create a separate secure route for refreshAccessToken.[got to user.routes.js]


# Writing update controllers for user :-
    > Here we create the basic structure of the subscription model.
    > What do you mean by subscription?
        - There is a channel that has subscribers.
        - Channel is a "user" and subscribers are also "users".
        - Create subscriptions.model.js .

    > Now we create some methods for user.controller.js .
        [changeCurrentPassword,getCurrentUser,updateAccountDetails,updateUserAvatar,updateUserCoverImage]

    > Todo:-Delete old images in "cloudinary".
        - Go to "cloudinary.js".

    > Professional approach :- When updating or deleting a file/image/PDF, create a separate controller for it instead of using it in the user controller.
        [For network congestion, we separate these files. But we can create it in the user.controller also.]


# Understand the subscription Schema :-
    > Why do we create a separate subscription schema?
        - In YouTube, we notice that each user has a subscriber count and a count of channels to which they are subscribed.
        - Channel is nothing but a "user" and subscribers are also "users".
        - We want to maintain these two functionality.
        - If we create an array to store the 'user_ids' of subscribers, we may encounter a problem when handling a very large number of subscribers, such as 1 million.
        - So we create separate schema.

    > In subscription schema, we have two major things i.e. a channel and a subscriber.

    > The question is, if you are not using an array to store the count of subscribed users and their information, how will you store that?

    > Follow notes to understand it properly.


# Learn Mongodb aggregation pipelines :-
    > Our main goal is to perform 'join'/'left join' operation between the 'user' and 'subscriptions' model.

    > We will learn about Mongodb aggregation pipeline.

    > Aggregation Pipeline :-
        - An aggregation pipeline consists of one or more stages that process documents:

            = Each stage performs an operation on the input documents. For example, a stage can filter documents, group documents, and calculate values.

            = The documents that are output from a stage are passed to the next stage.

            = An aggregation pipeline can return results for groups of documents. For example, return the total, average, maximum, and minimum values.

        - This section shows aggregation pipeline examples that use the following pizza orders collection:-
            db.orders.insertMany( [
                { _id: 0, name: "Pepperoni", size: "small", price: 19,
                    quantity: 10, date: ISODate( "2021-03-13T08:14:30Z" ) },
                { _id: 1, name: "Pepperoni", size: "medium", price: 20,
                    quantity: 20, date : ISODate( "2021-03-13T09:13:24Z" ) },
                { _id: 2, name: "Pepperoni", size: "large", price: 21,
                    quantity: 30, date : ISODate( "2021-03-17T09:22:12Z" ) },
                { _id: 3, name: "Cheese", size: "small", price: 12,
                    quantity: 15, date : ISODate( "2021-03-13T11:21:39.736Z" ) },
                { _id: 4, name: "Cheese", size: "medium", price: 13,
                    quantity:50, date : ISODate( "2022-01-12T21:23:13.331Z" ) },
                { _id: 5, name: "Cheese", size: "large", price: 14,
                    quantity: 10, date : ISODate( "2022-01-12T05:08:13Z" ) },
                { _id: 6, name: "Vegan", size: "small", price: 17,
                    quantity: 10, date : ISODate( "2021-01-13T05:08:13Z" ) },
                { _id: 7, name: "Vegan", size: "medium", price: 18,
                    quantity: 10, date : ISODate( "2021-01-13T05:10:13Z" ) }
            ] )

        - The following aggregation pipeline example contains two stages and returns the total order quantity of medium size pizzas grouped by pizza name:
            //Array ke bichh main likha jayega.
            db.orders.aggregate( [
                // Stage 1: Filter pizza order documents by pizza size
                {
                    $match: { size: "medium" }
                },

                // Stage 2: Group remaining documents by pizza name and calculate total quantity
                {
                    $group: { _id: "$name", totalQuantity: { $sum: "$quantity" } }
                }
            ] )

        - Now go mongoDB atlas and see "aggregate".
            > insert data in mongoDB atlas mode:-
                1.Click Insert Document.
                2.Click the {} icon, which opens the JSON view.
                3.Paste the document array into the text entry field.
                4.We will create two documents author and book.
                    author:
                        [
                            { "_id":100,"name":"Arjun","DOB":2002 },
                            { "_id":200,"name":"Prabhat","DOB":2001 },
                            { "_id":300,"name":"Amresh","DOB":2002 },
                            { "_id":400,"name":"Gourab","DOB":2001 }
                        ]
                    book:
                        [
                            {"_id":1,"author_id":100,"title":"A book","genre":"classical"},
                            {"_id":2,"author_id":200,"title":"B book","genre":"pop"},
                            {"_id":3,"author_id":300,"title":"C book","genre":"secondary"},
                            {"_id":4,"author_id":400,"title":"D book","genre":"filter"},
                        ]

            > We will join[left-join] books with author using the "lookup" function.
            > Select book document's aggregation section and then add aggregation-pipeline using '</>TEXT' format.
                [
                    {
                        $lookup: {
                            from: "author",
                            localField: "author_id",
                            foreignField: "_id",
                            as: "author_details",
                        },
                    },
                ]
            > The output of the aggregation pipelines comes in the form of arrays.

            > Suppose we want to return 1st element of an array.
                - We can add new fileds.
                    $addFields: {
                        author_details:{
                            $first:"$author_details"
                        }
                    }

                    OR

                    $addFields: {
                        author_details:{
                            $arrayElementAt:["$author_details",0]
                        }
                    }


    > Go to user.controller.js and see how to add aggregation pipelines for the user and subscriptions model..


# How to write sub pipelines and routes :-
    > We are creating a method to track the user's watch history.

    > Here we perform nested joining.
        - prefer E-R diagrame of all 'user' and 'video' models for better understanding. 
        - 'user' has watch history and it is an array of objectIDs of 'video' model.
        - In video model , every video is created by some user.
        - In the watch history, we aim to showcase both videos and their creators.
        - Agar hmm watch history main 'array of video-IDs' pane ke liye , 'user' model ko 'videos' model ke sath join karenge toh result document main videos ka owner[also an user] ka information hmme nahi milega.
        - Kyunki abhi takk hmne owner ko user model ke sath lookup nahi kiya hai.
        - means jisne ek perticular video ko create kiya hai uska information dooo.

        - So we perform nested 'left join'.

    > Go to user.controller.js and see watch_history method.

    > Adding routers for 'changeCurrentPassword','getCurrentUser','updateAccountDetails','updateUserAvatar','updateUserCoverImage','getUserChannelProfile','getWatchHistory'.


# MongoDB models for like , playlist and tweet :-